PORT=3001                                         # port to run the server on
REDIS_HOST=127.0.0.1                              # host of the redis server
REDIS_PORT=6379                                   # port of the redis server
MAX_CONCURRENT_REQUESTS=2                         # maximum number of concurrent requests per client
MAX_RAG_RESULTS=10                                # maximum number of similarity results to return in RAG model
COMPLETED_JOB_CLEANUP_DELAY=300000                # 1000 * 60 * 5 (5 minutes) ⇢ delay before completed jobs are removed from redis
INACTIVE_THRESHOLD=10000                          # 1000 * 5 (5 seconds) ⇢ interval between inactive client checks
CHROMA_SERVER_URL="http://127.0.0.1:8001"         # host of the chroma server
LLM_SERVER_URL="http://127.0.0.1:8080"            # URL of the LLM server
LLM_SERVER_TEMPERATURE=0.1                        # temperature of the LLM server
LLM_SERVER_STOP_TOKENS=["</s>", "LLM:", "USER:"]  # stop tokens of the LLM server
LLM_PROMPT_INSTRUCTIONS="Do not mention \"USER\" in your responses. This is a conversation between USER and LLM, a friendly chatbot. LLM is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision. Use the CONTEXT of this conversation to guide your responses accurately. If you do not know the answer simply answer 'I don't know'.\n\nCONTEXT:"
